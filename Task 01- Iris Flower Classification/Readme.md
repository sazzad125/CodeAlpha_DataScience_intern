# Iris Classification Project

## Overview
This project demonstrates a machine learning classification task using the Iris dataset. The goal is to classify Iris flowers into one of three species (Setosa, Versicolor, Virginica) based on their sepal and petal measurements. The dataset is analyzed, visualized, and used to train machine learning models, including Logistic Regression and Decision Tree classifiers.

## Dataset
The Iris dataset (`Iris.csv`) contains 150 samples with the following features:
- **Id**: Unique identifier for each sample
- **SepalLengthCm**: Sepal length in centimeters
- **SepalWidthCm**: Sepal width in centimeters
- **PetalLengthCm**: Petal length in centimeters
- **PetalWidthCm**: Petal width in centimeters
- **Species**: Target variable (Iris-setosa, Iris-versicolor, Iris-virginica)

The dataset is balanced, with 50 samples per species, and contains no missing values.

## Requirements
To run the code, ensure you have the following Python libraries installed:
- `pandas`
- `numpy`
- `matplotlib`
- `seaborn`
- `scikit-learn`

You can install them using pip:
```bash
pip install pandas numpy matplotlib seaborn scikit-learn
```

## Project Structure
The Jupyter notebook (`Iris.ipynb`) is organized as follows:
1. **Import Libraries**: Import necessary libraries for data manipulation, visualization, and modeling.
2. **Load Dataset**: Read the Iris dataset from `Iris.csv` using pandas.
3. **Exploratory Data Analysis (EDA)**:
   - Display the first few rows of the dataset.
   - Check column names and data types.
   - Verify there are no missing values.
   - Analyze class distribution (50 samples per species).
   - Visualize feature relationships using a pairplot with `seaborn`.
4. **Data Preprocessing**:
   - Split the dataset into features (X) and target (y).
   - Split data into training and testing sets using `train_test_split`.
   - Standardize features using `StandardScaler`.
5. **Model Training and Evaluation**:
   - Train a **Logistic Regression** model and evaluate its performance using accuracy, confusion matrix, and classification report.
   - Train a **Decision Tree Classifier** (with `random_state=42`) and evaluate its performance, achieving an accuracy of 1.0000 and perfect precision, recall, and F1-scores for all classes.

## How to Run
1. Ensure the `Iris.csv` dataset is in the same directory as the notebook.
2. Open the `Iris.ipynb` notebook in Jupyter Notebook or Google Colab.
3. Run the cells sequentially to load the data, perform EDA, preprocess the data, train the models, and view the results.
4. The pairplot visualization will display feature relationships, and the console output will show model performance metrics.

## Results
- **Decision Tree Classifier**:
  - **Accuracy**: 1.0000 (100% on the test set)
  - **Classification Report**:
    ```
                 precision    recall  f1-score   support
    setosa       1.00      1.00      1.00        10
    versicolor    1.00      1.00      1.00        10
    virginica     1.00      1.00      1.00        10
    accuracy                            1.00        30
    macro avg     1.00      1.00      1.00        30
    weighted avg  1.00      1.00      1.00        30
    ```

The Decision Tree Classifier achieves perfect classification on the test set, indicating excellent separation of the Iris species based on the provided features.

## Notes
- The Iris dataset is a simple, well-structured dataset, making it ideal for demonstrating classification algorithms.
- The pairplot generated by `seaborn` helps visualize the separability of classes based on feature pairs.
- The `random_state=42` ensures reproducibility of the Decision Tree results.
- Additional models (e.g., SVM, Random Forest) or hyperparameter tuning could be explored for further analysis.

## Author
Md Sazzad Hossen

## License
This project is for educational purposes and uses the publicly available Iris dataset. Feel free to modify and use the code as needed.
